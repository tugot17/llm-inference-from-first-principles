{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr_mazurek/.cache/pypoetry/virtualenvs/llm-inference-from-first-principles-fQ50PtHD-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.95s/it]\n",
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n",
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n",
      "Model dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "\n",
    "# Load the model in FP16 and move it to CUDA\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded on: {device}\")\n",
    "print(f\"Model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n",
      "Model dtype: torch.float16\n",
      "Total number of parameters: 8,030,261,248\n",
      "\n",
      "Analyzing model layers...\n",
      "lm_head: 525,336,576 parameters\n",
      "model.embed_tokens: 525,336,576 parameters\n",
      "model.norm: 4,096 parameters\n",
      "model.layers.0.input_layernorm: 4,096 parameters\n",
      "model.layers.0.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.0.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.0.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.0.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.0.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.0.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.0.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.0.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.1.input_layernorm: 4,096 parameters\n",
      "model.layers.1.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.1.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.1.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.1.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.1.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.1.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.1.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.1.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.2.input_layernorm: 4,096 parameters\n",
      "model.layers.2.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.2.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.2.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.2.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.2.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.2.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.2.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.2.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.3.input_layernorm: 4,096 parameters\n",
      "model.layers.3.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.3.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.3.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.3.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.3.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.3.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.3.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.3.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.4.input_layernorm: 4,096 parameters\n",
      "model.layers.4.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.4.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.4.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.4.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.4.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.4.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.4.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.4.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.5.input_layernorm: 4,096 parameters\n",
      "model.layers.5.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.5.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.5.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.5.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.5.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.5.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.5.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.5.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.6.input_layernorm: 4,096 parameters\n",
      "model.layers.6.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.6.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.6.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.6.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.6.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.6.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.6.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.6.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.7.input_layernorm: 4,096 parameters\n",
      "model.layers.7.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.7.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.7.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.7.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.7.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.7.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.7.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.7.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.8.input_layernorm: 4,096 parameters\n",
      "model.layers.8.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.8.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.8.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.8.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.8.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.8.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.8.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.8.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.9.input_layernorm: 4,096 parameters\n",
      "model.layers.9.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.9.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.9.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.9.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.9.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.9.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.9.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.9.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.10.input_layernorm: 4,096 parameters\n",
      "model.layers.10.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.10.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.10.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.10.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.10.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.10.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.10.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.10.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.11.input_layernorm: 4,096 parameters\n",
      "model.layers.11.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.11.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.11.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.11.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.11.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.11.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.11.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.11.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.12.input_layernorm: 4,096 parameters\n",
      "model.layers.12.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.12.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.12.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.12.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.12.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.12.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.12.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.12.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.13.input_layernorm: 4,096 parameters\n",
      "model.layers.13.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.13.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.13.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.13.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.13.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.13.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.13.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.13.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.14.input_layernorm: 4,096 parameters\n",
      "model.layers.14.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.14.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.14.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.14.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.14.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.14.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.14.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.14.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.15.input_layernorm: 4,096 parameters\n",
      "model.layers.15.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.15.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.15.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.15.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.15.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.15.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.15.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.15.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.16.input_layernorm: 4,096 parameters\n",
      "model.layers.16.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.16.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.16.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.16.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.16.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.16.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.16.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.16.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.17.input_layernorm: 4,096 parameters\n",
      "model.layers.17.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.17.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.17.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.17.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.17.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.17.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.17.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.17.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.18.input_layernorm: 4,096 parameters\n",
      "model.layers.18.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.18.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.18.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.18.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.18.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.18.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.18.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.18.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.19.input_layernorm: 4,096 parameters\n",
      "model.layers.19.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.19.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.19.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.19.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.19.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.19.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.19.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.19.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.20.input_layernorm: 4,096 parameters\n",
      "model.layers.20.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.20.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.20.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.20.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.20.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.20.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.20.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.20.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.21.input_layernorm: 4,096 parameters\n",
      "model.layers.21.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.21.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.21.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.21.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.21.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.21.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.21.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.21.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.22.input_layernorm: 4,096 parameters\n",
      "model.layers.22.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.22.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.22.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.22.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.22.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.22.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.22.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.22.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.23.input_layernorm: 4,096 parameters\n",
      "model.layers.23.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.23.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.23.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.23.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.23.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.23.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.23.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.23.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.24.input_layernorm: 4,096 parameters\n",
      "model.layers.24.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.24.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.24.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.24.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.24.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.24.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.24.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.24.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.25.input_layernorm: 4,096 parameters\n",
      "model.layers.25.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.25.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.25.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.25.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.25.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.25.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.25.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.25.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.26.input_layernorm: 4,096 parameters\n",
      "model.layers.26.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.26.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.26.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.26.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.26.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.26.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.26.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.26.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.27.input_layernorm: 4,096 parameters\n",
      "model.layers.27.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.27.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.27.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.27.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.27.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.27.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.27.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.27.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.28.input_layernorm: 4,096 parameters\n",
      "model.layers.28.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.28.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.28.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.28.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.28.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.28.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.28.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.28.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.29.input_layernorm: 4,096 parameters\n",
      "model.layers.29.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.29.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.29.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.29.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.29.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.29.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.29.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.29.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.30.input_layernorm: 4,096 parameters\n",
      "model.layers.30.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.30.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.30.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.30.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.30.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.30.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.30.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.30.self_attn.v_proj: 4,194,304 parameters\n",
      "model.layers.31.input_layernorm: 4,096 parameters\n",
      "model.layers.31.mlp.down_proj: 58,720,256 parameters\n",
      "model.layers.31.mlp.gate_proj: 58,720,256 parameters\n",
      "model.layers.31.mlp.up_proj: 58,720,256 parameters\n",
      "model.layers.31.post_attention_layernorm: 4,096 parameters\n",
      "model.layers.31.self_attn.k_proj: 4,194,304 parameters\n",
      "model.layers.31.self_attn.o_proj: 16,777,216 parameters\n",
      "model.layers.31.self_attn.q_proj: 16,777,216 parameters\n",
      "model.layers.31.self_attn.v_proj: 4,194,304 parameters\n",
      "\n",
      "Summary of top-level modules:\n",
      "model: 7,504,924,672 parameters\n",
      "lm_head: 525,336,576 parameters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Dict\n",
    "import re\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def analyze_model_layers(model: nn.Module) -> Dict[str, int]:\n",
    "    layer_params: Dict[str, int] = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if len(list(module.children())) == 0:  # If it's a leaf module\n",
    "            num_params = sum(p.numel() for p in module.parameters())\n",
    "            if num_params > 0:\n",
    "                layer_params[name] = num_params\n",
    "    return layer_params\n",
    "\n",
    "def extract_layer_id(layer_name: str) -> tuple:\n",
    "    match = re.search(r'layers\\.(\\d+)', layer_name)\n",
    "    if match:\n",
    "        return (int(match.group(1)), layer_name)\n",
    "    return (-1, layer_name)  # For non-numbered layers\n",
    "\n",
    "# Assuming 'model' is already loaded and available in your notebook\n",
    "# Print basic model info\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "print(f\"Model dtype: {next(model.parameters()).dtype}\")\n",
    "\n",
    "# Count and print the total number of parameters\n",
    "total_params: int = count_parameters(model)\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "# Analyze and print the number of parameters in each layer\n",
    "print(\"\\nAnalyzing model layers...\")\n",
    "layer_params = analyze_model_layers(model)\n",
    "\n",
    "# Sort layers by layer ID and then by name\n",
    "sorted_layers = sorted(layer_params.items(), key=lambda x: extract_layer_id(x[0]))\n",
    "\n",
    "# Print sorted layers\n",
    "for layer_name, num_params in sorted_layers:\n",
    "    print(f\"{layer_name}: {num_params:,} parameters\")\n",
    "\n",
    "# Print summary of top-level modules\n",
    "print(\"\\nSummary of top-level modules:\")\n",
    "for name, module in model.named_children():\n",
    "    num_params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name}: {num_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-inference-from-first-principles-fQ50PtHD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
